## How it works
Peer review —where experts evaluate a researcher's new findings— is the foundation of scientific communication. However, this crucial process is slow, expensive, and inequitable because it remains confined within journals that follow an antiquated publishing system. Journal editors routinely cite the difficulty of finding reviewers as their main production bottleneck, with publication delays often caused by unanswered invitations and overdue reviews. At the heart of the problem is an outdated system that depends on mass email requests pressuring the same small, overburdened group of scholars to work for free. 


**PaperStacks** addresses the peer-review bottleneck by replacing goodwill-based solicitation methods with a structured, incentive-driven system. Instead of relying on mass emails, the platform offers each reviewer a personalized, continuously updated feed of papers seeking peer review within their field(s) of expertise. For every completed review, researchers earn credits linked to their profile, which can later be spent to request peer reviews of their own papers. This creates a self-balancing ecosystem where no one can publish without first contributing. This ensures that the platform never outpaces its capacity, preventing reviewer fatigue. 
On the platform, competitive incentives favor quality over quantity of peer reviews. Users are nudged to focus on a few high-quality reviews, as a history of good performance allows users to gain more tokens per review. Overall, peer review is managed by incentives and competition, not editorial mandates. On PaperStacks, editorial oversight is minimal and focused on dispute resolution. Furthermore, our editors are elevated users rewarded with tokens and privileges, not institutional gatekeepers. Unlike legacy publishers that sylo research into journals with bloated overhead, our platform scales naturally across disciplines. Its personalized feed and user-defined review settings offer flexibility, allowing each field to apply its standards without the platform enforcing uniformity. 
![Figure of the entire system](/PS%20short%20pitch.svg)

**1. Creating Peer Review Activities** Authors can initiate a peer review activity to coordinate the evaluation of their paper. They may share the full manuscript (e.g. a preprint) or selected excerpts such as the abstract or methods section. The author sets the number of required reviewers, the number of review rounds, and additional parameters, such as whether the process will be anonymous for the author and reviewers. More settings will be discussed in a leter stage.

**2. Selecting Papers to Review** Users can browse their feed and choose papers to review based on both the content and the review settings defined by the author. Once a user selects a paper, they join the review team and are given a limited window (e.g. 48 hours) to submit their review. If they miss the deadline, the opportunity is opened to others. This short timeframe is designed to ensure that users only commit when they actually have time to review, thus increasing reliability and speed.

**3. Review Process and Evaluation Rounds** Each round involves all reviewers submitting their evaluations and notes to the author. Once all feedback is in, the author can respond with a rebuttal and an updated version of the paper. Evaluations from the round are then revealed to the rest of the reviewer team.

If more rounds remain, the process repeats. In the final round, reviewers must collectively draft a short assessment of the revised paper, incorporating their own feedback, insights from others, and the author’s revisions. Reviewers do not need to agree—disagreements can be reflected in the final assessment. This consensus document serves as a qualitative evaluation of the paper and plays a role in later stages.

**4. Mutual Awarding and Token Incentives** Once the final assessments are written, one final step remains: mutual awarding. Reviewers distribute a set of predefined awards to each other (self-awarding is not allowed), each carrying specific point values. Examples include:

- Insightful Analysis - Identifies the paper’s core contribution with original insight (50 points)

- Paper Challenger - Critiques key weaknesses constructively (100 points)

- Clarity Champion - Provides clear, structured arguments (50 points)

- Methodology Mentor - Spots methodological flaws or suggests improvements (75 points)

After all awards are distributed, points are tallied, and reviewers are ranked. Token rewards are distributed based on rank, incentivizing constructive, high-quality reviews. The system encourages reviewers to perform well; poor reviews yield fewer tokens, meaning more reviews are needed to earn enough for one’s own submissions. In this way, the platform naturally rewards quality over quantity.

**5. Using Tokens to Launch New Review Activities** Reviewers who accumulate enough tokens can launch peer review activities for their papers. Beyond the standard settings, authors may also add reviewer eligibility filters—for example, requiring reviewers to have ranked first in past activities. This adds a reputational layer, promoting consistent quality and creating a competitive incentive structure where excellence in reviewing leads to greater visibility and opportunities.

**6. Publishing Reviewed Papers on PaperStacks** Once a peer review activity is complete, the author receives a fully reviewed version of their paper, accompanied by assessments and reviewer reputations. They may choose to publish this version on the PaperStacks library, making it freely available to the public.

**7. Journal Compatibility and Fast-Track Publishing** PaperStacks recognizes the career and funding pressures researchers face. That’s why we prioritize compatibility with journals that accept pre-reviewed submissions. A list of such journals is included in the ‘resources’ section. While our goal is to offer a journal-independent, high-quality peer review service, we also support authors who want to fast-track their work toward journal publication through trusted, community-driven validation.


## Strategy
To avoid clashing with the bibliometric and reputational incentives that still govern academic careers, **PaperStacks** will use its superior peer-review system to support entrenched journals, rather than replace them. It offers "pre-reviewed papers" complete with reviews, reviewer assessments, and author responses, all formatted for easy journal integration. With PaperStacks, editors gain access to fully vetted, reviewed papers, which reduces production costs and decision times. Authors can easily export their "pre-reviewed packages" to established journals, maintaining access to the prestige and recognition needed for career advancement. Numerous journals already accept externally pre-reviewed submissions, committing not to repeat peer review unnecessarily. 

Our growth strategy capitalizes on two defining characteristics of the academic landscape. (i) Research is fragmented into myriad specialized niches —a key reason major publishers operate thousands of distinct journals. This fragmentation allows **PaperStacks** to develop a replicable niche- specific growth playbook that can be deployed in parallel across multiple fields. (ii) Within each niche, a minority of researchers are responsible for the majority of reviews. **PaperStacks** will identify and proactively onboard these prolific reviewers, offering them relevant preprints to review and rewarding them with credits. By giving these reviewers tangible recognition, we create a strong incentive that surpasses the intangible social capital traditionally provided by journal editors. Reviews produced by this proactive approach are then shared on preprint servers, surprising authors with valuable feedback, prompting them to join **PaperStacks** and creating a self-sustaining cycle.

Given that **PaperStacks** reviews are free to editors and authors, while actively rewarding reviewers, early-adopting journals within each niche will quickly embrace this streamlined workflow. As adoption increases, rival journals will face greater difficulty sourcing reviewers independently, eventually compelling them to accept pre-reviewed papers to remain competitive. By repeatedly applying this strategy niche-by-niche, **PaperStacks** transforms reviewer scarcity into leverage, gradually shifting the default peer review pipeline toward its platform.

**PaperStacks** will follow a two-stage revenue path. First, we run a freemium model for researchers: core peer-review functions and review-earned tokens stay free. By paying, users receive priority placement of their manuscripts in reviewer feeds, rich analytics, and tools to launch other activities beyond peer review (e.g., curation activities). Once a field reaches critical mass—meaning editors are sourcing most of their manuscripts pre-reviewed on PaperStacks—we shift to the second stage: publisher agreements. At that point, journals save significant time and money by importing **PaperStacks** review packages, so we license seamless API integrations, branded report formats, and portfolio-level analytics under annual or per-paper contracts. In short, individual subscriptions generate early cash flow and platform loyalty, while downstream B2B deals with publishers capture the larger efficiency gains once dependence on **PaperStacks** is established. 

## The Team
I am Rodrigo Rosas-Bertolini, the founder and developer of PaperStacks, and I am looking for a co-founder to disrupt the heck out of the 40+ billion £ academic publishing industry. 

I hold a Master's degree in Molecular and Cellular Life Sciences from Utrecht University, where I specialized in developmental genetics. After graduating, I decided to part ways with the wet lab and worked as a software engineer focused on microscopy data management. Although my stay in research was short, it was enough to form the conviction that the publishing experience is terrible because reviewers are not remunerated. No explanations from my peer to excuse this design flaw were satisfying, but I did not have the time to delve into the problem.

Fortunately, while working in software, I decided to pursue a Master's in Business Administration at the Amsterdam Business School. For my thesis, I conducted a case study on the life sciences publisher eLife. Through in-depth interviews with leaders of the publishing industry, I saw the publishing ecosystem from the inside—and realized I had a fundamentally different vision of what academic publishing could and should be than even the most avant-garde of them. This convinced me to follow through with my nagging intuition. I am now building a platform and intend to move to Brussels to grow the company there.

This is an open invitation for anyone in Belgium. If what you’ve read here resonates with you, whatever your background, I’d love to hear from you.

Remember, paper stacks are for researchers.

## Timeline
I'm working hard to finish V1 of the platform. 

I intend to go live in Septmeber 3rd.

Soon I hope to open inscriptions for alpha testing.

Contact me for a demo!

## Resources